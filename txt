conda activate py310
code2prompt -p /home/zhixuanhu/IEDA_WeightedTraining/RealdataEXP -o /home/zhixuanhu/IEDA_WeightedTraining/RealdataEXP_prompt_202508141524.md --line-number -e "**/KuaiRand/*,**/results/*,**/__pycache__/*,**/.ipynb_checkpoints/*,**/.vscode/*,*.pt,*.pth,*.zip,*.tar.gz,*.log,**/venv/*,**/env/*"
code2prompt -p E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP -o E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP_prompt_202508180044.md --line-number -e "**/KuaiRand/*,**/results/*,**/__pycache__/*,**/.ipynb_checkpoints/*,**/.vscode/*,*.pt,*.pth,*.zip,*.tar.gz,*.log,**/venv/*,**/env/*"
code2prompt -p /home/export/base/sc100352/sc100352/online1/IEDA_WeightedTraining/RealdataEXP -o /home/export/base/sc100352/sc100352/online1/IEDA_WeightedTraining/RealdataEXP_prompt_202508220924.md --line-number -e "**/KuaiRand/*,**/results/*,**/__pycache__/*,**/.ipynb_checkpoints/*,**/.vscode/*,*.pt,*.pth,*.zip,*.tar.gz,*.log,**/venv/*,**/env/*"


cd /home/export/base/sc100352/sc100352/online1/IEDA_WeightedTraining
git config --global credential.helper libsecret
git add -A
git rm -r --cached .
git commit -m "push deleted"
git push

conda activate E:\MyDocument\Codes_notnut\_notpad\IEDA\.conda
cd RealdataEXP
conda activate intelxpu
conda activate pytorchDML
python main.py --config configs/experiment_optimized.yaml

conda create -n ieda python=3.12  
python -m ipykernel install --user --name coquiTTS --display-name "coquiTTS"                                              


预训练阶段一个epoch的32819是什么意思；
训练：batch_size:64
计算：批次总数是样本总数除以批次大小，四舍五入得到最接近的整数。
计算：2,100,391 个样本 ÷64 个样本 / 批次 = 32818.6
四舍五入得到总批次数为 32819。



ipex不开amp会报错
val时是不是还有优化
https://intel.github.io/intel-extension-for-pytorch/xpu/2.8.10+xpu/tutorials/examples.html

:\miniconda\envs\intelxpu\Lib\site-packages\intel_extension_for_pytorch\xpu\amp\autocast_mode.py:22: UserWarning: torch.xpu.amp.autocast is deprecated. Please use torch.amp.autocast('xpu') instead.
  warnings.warn(


(intelxpu) PS E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP> python main.py --config configs/experiment_optimized.yaml
[W818 09:26:46.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
2025-08-18 09:26:48 - root - INFO - ============================================================
2025-08-18 09:26:48 - root - INFO - RealdataEXP 实验框架启动
2025-08-18 09:26:48 - root - INFO - ============================================================
2025-08-18 09:26:48 - root - INFO - 实验模式: global_optimized
2025-08-18 09:26:48 - root - INFO - 设备选择 (来自配置): auto
2025-08-18 09:26:48 - root - INFO - 实验目录: E:/MyDocument/Codes_notnut/_notpad/IEDA/RealdataEXP\results\20250818_0926
2025-08-18 09:26:48 - root - INFO - 配置文件: E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP\configs/experiment_optimized.yaml 
2025-08-18 09:26:48 - root - INFO - [模式选择] 运行Global模式优化实验
2025-08-18 09:26:48 - libs.utils.device_utils - INFO - [Device] Intel IPEX is available. Using XPU backend (Full IPEX Optimization & AMP).
2025-08-18 09:26:48 - libs.modes.global_mode_optimized - INFO - [Global模式优化] 初始化完成，设备: xpu, AMP: True
2025-08-18 09:26:48 - libs.modes.global_mode_optimized - INFO - [Global模式优化] 开始运行完整实验...
2025-08-18 09:26:48 - libs.utils.gpu_utils - WARNING - [GPU检查] CUDA不可用，将使用CPU运行
2025-08-18 09:26:48 - libs.utils.gpu_utils - WARNING - [GPU速度测试] CUDA不可用，跳过测试
2025-08-18 09:26:48 - libs.modes.global_mode_optimized - INFO - [Global模式优化] 开始数据加载和准备...
2025-08-18 09:26:48 - libs.data.data_loader - INFO - [数据准备] 开始数据加载和准备流程...
2025-08-18 09:26:48 - libs.data.data_loader - INFO - [数据加载] 开始加载所有数据文件...
2025-08-18 09:26:48 - libs.data.data_loader - INFO - [数据加载] (1/6) 正在加载 log_random: data/log_random_4_22_to_5_08_pure.csv    
2025-08-18 09:26:49 - libs.data.data_loader - INFO - [数据加载] log_random 加载完成，形状: (1186059, 19)
2025-08-18 09:26:49 - libs.data.data_loader - INFO - [数据加载] (2/6) 正在加载 log_standard_early: data/log_standard_4_08_to_4_21_pure.csv
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] log_standard_early 加载完成，形状: (1141112, 19)
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] (3/6) 正在加载 log_standard_late: data/log_standard_4_22_to_5_08_pure.csv
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] log_standard_late 加载完成，形状: (295497, 19)
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] (4/6) 正在加载 user_features: data/user_features_pure.csv
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] user_features 加载完成，形状: (27285, 31)
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] (5/6) 正在加载 video_basic: data/video_features_basic_pure.csv
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] video_basic 加载完成，形状: (7583, 12)
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] (6/6) 正在加载 video_statistic: data/video_features_statistic_pure.csv
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] video_statistic 加载完成，形状: (7583, 52)
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据加载] 所有数据文件加载完成
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据合并] 合并多个日志文件...
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [数据合并] 合并后日志数据形状: (2622668, 19)
2025-08-18 09:26:50 - libs.data.data_loader - INFO - [特征合并] 开始合并用户和视频特征...
2025-08-18 09:26:51 - libs.data.data_loader - INFO - [特征合并] 合并用户特征后形状: (2622668, 49)
2025-08-18 09:26:52 - libs.data.data_loader - INFO - [特征合并] 合并视频基础特征后形状: (2622668, 60)
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [特征合并] 合并视频统计特征后形状: (2622668, 111)
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [特征合并] 特征合并完成
2025-08-18 09:26:54 - libs.data.cache_manager - INFO - [缓存] 数据已加载: user_video_lists
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [缓存] 从缓存加载用户-视频交互列表
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [用户划分] 开始划分用户，验证集比例: 0.2
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [用户划分] 训练用户数: 21828, 验证用户数: 5457
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [标记位] 添加mask和used标记位...
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [标记位] mask=1的样本数: 532211/2622668 (20.29%)
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [标记位] 标记位添加完成
2025-08-18 09:26:54 - libs.data.data_loader - INFO - [数据准备] 数据准备流程完成
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [数据统计] total_samples: 2622668
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [数据统计] unique_users: 27285
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [数据统计] unique_videos: 7583
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [数据统计] train_users: 21828
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [数据统计] val_users: 5457
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [数据统计] click_rate: 0.3314472132957736
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [数据统计] avg_play_time: 15676.53942435718
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [数据统计] features_used: {'numerical': ['video_duration', 'server_width', 'server_height', 'show_cnt', 'play_cnt', 'play_user_num', 'complete_play_cnt', 'like_cnt', 'comment_cnt', 'share_cnt', 'collect_cnt', 'is_live_streamer', 'is_video_author', 'follow_user_num', 'fans_user_num', 'friend_user_num', 'register_days'], 'categorical': ['user_active_degree', 'video_type', 'tag']}
2025-08-18 09:26:54 - libs.modes.global_mode_optimized - INFO - [特征处理] 开始特征预处理...
2025-08-18 09:26:54 - libs.data.feature_processor - INFO - [特征处理] 开始特征拟合和转换...
2025-08-18 09:26:54 - libs.data.feature_processor - INFO - [特征处理] 处理缺失值...
2025-08-18 09:26:55 - libs.data.feature_processor - INFO - [特征处理] video_duration: 用0填充 65794 个缺失值
2025-08-18 09:26:56 - libs.data.feature_processor - INFO - [特征处理] tag: 将 28107 个缺失值标记为'MISSING'
2025-08-18 09:26:56 - libs.data.feature_processor - INFO - [特征处理] 缺失值处理完成
2025-08-18 09:26:56 - libs.data.feature_processor - INFO - [特征处理] 处理分类特征...
2025-08-18 09:26:57 - libs.data.feature_processor - INFO - [特征处理] user_active_degree: 9 个唯一值
2025-08-18 09:26:59 - libs.data.feature_processor - INFO - [特征处理] user_active_degree -> 9 个one-hot特征
2025-08-18 09:26:59 - libs.data.feature_processor - INFO - [特征处理] video_type: 3 个唯一值
2025-08-18 09:27:01 - libs.data.feature_processor - INFO - [特征处理] video_type -> 3 个one-hot特征
2025-08-18 09:27:01 - libs.data.feature_processor - INFO - [特征处理] tag: 111 个唯一值
2025-08-18 09:27:03 - libs.data.feature_processor - INFO - [特征处理] tag -> 111 个one-hot特征
2025-08-18 09:27:03 - libs.data.feature_processor - INFO - [特征处理] 分类特征处理完成，总维度: 123
2025-08-18 09:27:03 - libs.data.feature_processor - INFO - [特征处理] 处理数值特征...
2025-08-18 09:27:04 - libs.data.feature_processor - WARNING - [特征处理] 缺失的数值特征: ['follow_user_num']
2025-08-18 09:27:05 - libs.data.feature_processor - INFO - [特征处理] 数值特征标准化器已拟合，特征数: 16
2025-08-18 09:27:05 - libs.data.feature_processor - INFO - [特征处理] 数值特征标准化完成，维度: 16
2025-08-18 09:27:05 - libs.data.feature_processor - INFO - [特征处理] 特征处理完成，总维度: 139 (数值: 16, 分类: 123)
2025-08-18 09:27:06 - libs.data.feature_processor - INFO - [特征处理] 数据类型转换完成
2025-08-18 09:27:06 - libs.modes.global_mode_optimized - INFO - [特征处理] 特征维度: 139
2025-08-18 09:27:06 - libs.modes.global_mode_optimized - INFO - [特征处理] 特征列: ['video_duration', 'server_width', 'server_height', 'show_cnt', 'play_cnt', 'play_user_num', 'complete_play_cnt', 'like_cnt', 'comment_cnt', 'share_cnt', 'collect_cnt', 'is_live_streamer', 'is_video_author', 'fans_user_num', 'friend_user_num', 'register_days', 'user_active_degree_2_14_day_new', 'user_active_degree_30day_retention', 'user_active_degree_UNKNOWN', 'user_active_degree_day_new', 'user_active_degree_full_active', 'user_active_degree_high_active', 'user_active_degree_low_active', 'user_active_degree_middle_active', 'user_active_degree_single_low_active', 'video_type_AD', 'video_type_NORMAL', 'video_type_UNKNOWN', 'tag_1', 'tag_1,62', 'tag_10', 'tag_10,60', 'tag_11', 'tag_11,60', 'tag_12', 'tag_12,54', 'tag_12,54,60', 'tag_12,60', 'tag_12,62', 'tag_12,62,42', 'tag_12,62,60', 'tag_12,65', 'tag_12,65,60', 'tag_13', 'tag_13,62', 'tag_13,65', 'tag_14', 'tag_15', 'tag_15,67', 'tag_16', 'tag_17', 'tag_18', 'tag_19', 'tag_2', 'tag_20', 'tag_20,43', 'tag_20,54', 'tag_20,67', 'tag_20,67,68', 'tag_20,68', 'tag_21', 'tag_22', 'tag_23', 'tag_24', 'tag_25', 'tag_25,54', 'tag_25,65', 'tag_25,67', 'tag_26', 'tag_26,62', 'tag_26,65', 'tag_26,67', 'tag_27', 'tag_27,42', 'tag_27,42,54', 'tag_27,54', 'tag_27,67', 'tag_28', 'tag_29', 'tag_3', 'tag_3,42', 'tag_3,62', 'tag_3,62,42', 'tag_3,67', 'tag_30', 'tag_34', 'tag_35', 'tag_36', 'tag_37', 'tag_38', 'tag_39', 'tag_39,43', 'tag_39,68', 'tag_39,9', 'tag_4', 'tag_40,39', 'tag_42,18', 'tag_42,4', 'tag_42,60,18', 'tag_5', 'tag_5,42', 'tag_5,42,60', 'tag_5,54', 'tag_5,65', 'tag_5,65,42', 'tag_5,67', 'tag_56,39', 'tag_6', 'tag_62,10,60', 'tag_62,16', 'tag_62,18', 'tag_62,2', 'tag_62,27', 'tag_62,27,42', 'tag_62,4', 'tag_62,42,18', 'tag_62,42,4', 'tag_62,5', 'tag_62,5,42', 'tag_62,65,4', 'tag_62,7', 'tag_65,11', 'tag_65,18', 'tag_65,27,42', 'tag_65,36', 'tag_65,4', 'tag_65,42,18', 'tag_67,11', 'tag_67,19', 'tag_67,34', 'tag_67,4', 'tag_67,6', 'tag_67,7', 'tag_68,6', 'tag_7', 'tag_8', 'tag_8,67', 'tag_9', 'tag_MISSING']
2025-08-18 09:27:06 - libs.models.multi_label_model - INFO - [模型构建] 开始构建多标签预测模型...
2025-08-18 09:27:06 - libs.models.multi_label_model - INFO - [模型构建] 构建 play_time 模型...
2025-08-18 09:27:06 - libs.models.multi_label_model - INFO - [模型构建] play_time 模型: 79105 参数
2025-08-18 09:27:06 - libs.models.multi_label_model - INFO - [模型构建] 构建 click 模型...
2025-08-18 09:27:06 - libs.models.multi_label_model - INFO - [模型构建] click 模型: 28801 参数
2025-08-18 09:27:06 - libs.models.multi_label_model - INFO - [模型构建] 多标签模型构建完成，共 2 个模型
2025-08-18 09:27:06 - libs.modes.global_mode_optimized - INFO - [IPEX] Applying ipex.optimize() to all models and optimizers...     
2025-08-18 09:27:06,494 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd
2025-08-18 09:27:06,564 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd
2025-08-18 09:27:06 - libs.modes.global_mode_optimized - INFO - [IPEX] ipex.optimize() applied successfully.
2025-08-18 09:27:06 - libs.modes.global_mode_optimized - INFO - [Global模式优化] 数据准备完成
2025-08-18 09:27:06 - libs.modes.global_mode_optimized - INFO - [预训练优化] 开始预训练阶段...
2025-08-18 09:27:14 - libs.modes.global_mode_optimized - INFO - [预训练优化] 数据划分完成 - 训练集: 1045228, 验证集: 1045229
2025-08-18 09:27:19 - libs.modes.global_mode_optimized - INFO - [数据集] 创建TabularDataset，样本数: 1045228, 特征维度: 139
2025-08-18 09:27:19 - libs.modes.global_mode_optimized - INFO - [DataLoader] 创建完成 - batch_size: 64, num_workers: 12, pin_memory: False
2025-08-18 09:27:24 - libs.modes.global_mode_optimized - INFO - [数据集] 创建TabularDataset，样本数: 1045229, 特征维度: 139
2025-08-18 09:27:24 - libs.modes.global_mode_optimized - INFO - [DataLoader] 创建完成 - batch_size: 64, num_workers: 12, pin_memory: False
2025-08-18 09:27:24 - libs.modes.global_mode_optimized - INFO - [预训练优化] Epoch 1/150
Epoch 1 Training:   0%|                                                                                  | 0/16332 [00:00<?, ?it/s][W818 09:27:29.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:29.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:29.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:29.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:30.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:30.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:30.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:30.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:31.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:31.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:31.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:27:32.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
E:\miniconda\envs\intelxpu\Lib\site-packages\intel_extension_for_pytorch\xpu\amp\autocast_mode.py:22: UserWarning: torch.xpu.amp.autocast is deprecated. Please use torch.amp.autocast('xpu') instead.
  warnings.warn(
Epoch 1 Training: 100%|██████████████████| 16332/16332 [02:30<00:00, 108.64it/s, play_time=3.3639, click=0.6249, batch_time=0.009s]
2025-08-18 09:29:54 - libs.modes.global_mode_optimized - INFO - [预训练优化] Epoch 1 训练完成，用时: 150.33秒 - 平均损失: train_play_time: 3.027793, train_click: 0.615449
2025-08-18 09:29:54 - libs.modes.global_mode_optimized - INFO - [预训练优化] Epoch 1 吞吐量: 6953 样本/秒
[W818 09:30:01.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:01.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:01.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:02.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:02.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:04.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:04.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:04.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:04.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:05.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:05.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
[W818 09:30:05.000000000 OperatorEntry.cpp:225] Warning: Warning only once for all operators,  other operators may also be overridden.
  Overriding a previously registered kernel for the same operator and the same dispatch key
  operator: aten::geometric_(Tensor(a!) self, float p, *, Generator? generator=None) -> Tensor(a!)
    registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\build\aten\src\ATen\RegisterSchema.cpp:6
  dispatch key: XPU
  previous kernel: registered at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\VmapModeRegistrations.cpp:37
       new kernel: registered at E:\frameworks.ai.pytorch.ipex-gpu\build\Release\csrc\gpu\csrc\gpu\xpu\ATen\RegisterXPU_0.cpp:172 (function operator ())
2025-08-18 09:30:54 - libs.modes.global_mode_optimized - INFO - [预训练优化] Epoch 1 验证完成 - 平均损失: val_play_time: 2.985853, val_click: 0.609662
2025-08-18 09:30:54 - libs.models.multi_label_model - INFO - [模型保存] 模型已保存到: E:/MyDocument/Codes_notnut/_notpad/IEDA/RealdataEXP\results\20250818_0926\checkpoints\pretrain_epoch_1.pt
2025-08-18 09:30:54 - libs.modes.global_mode_optimized - INFO - [预训练保存] Epoch 1 的模型已保存到checkpoints目录
2025-08-18 09:30:55 - libs.modes.global_mode_optimized - INFO - [预训练绘图] 损失曲线图已保存到: E:/MyDocument/Codes_notnut/_notpad/IEDA/RealdataEXP\results\20250818_0926\pretrain_loss_curves.png
2025-08-18 09:30:55 - libs.modes.global_mode_optimized - INFO - [预训练优化] Epoch 2/150
Epoch 2 Training:   0%|                                                                                  | 0/16332 [00:00<?, ?it/s]E:\miniconda\envs\intelxpu\Lib\site-packages\intel_extension_for_pytorch\xpu\amp\autocast_mode.py:22: UserWarning: torch.xpu.amp.autocast is deprecated. Please use torch.amp.autocast('xpu') instead.
  warnings.warn(
Epoch 2 Training:  24%|████▉               | 4001/16332 [00:47<02:27, 83.46it/s, play_time=4.6070, click=0.5787, batch_time=0.006s]
2025-08-18 09:31:43 - libs.modes.global_mode_optimized - ERROR - [Global模式优化] 实验执行失败: Caught RuntimeError in DataLoader worker process 5.
Original Traceback (most recent call last):
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ~~~~~~~~~~~~~~~^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 212, in collate
    collate(samples, collate_fn_map=collate_fn_map)
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 155, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 270, in collate_tensor_fn
    storage = elem._typed_storage()._new_shared(numel, device=elem.device)
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\storage.py", line 1203, in _new_shared
    untyped_storage = torch.UntypedStorage._new_shared(
        size * self._element_size(), device=device
    )
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\storage.py", line 414, in _new_shared
    return cls._new_using_filename_cpu(size)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
RuntimeError: Couldn't open shared file mapping: <torch_33852_2861069063_5082>, error code: <1455>
Traceback (most recent call last):
  File "E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP\libs\modes\global_mode_optimized.py", line 715, in run
    self.pretrain_models_optimized()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP\libs\modes\global_mode_optimized.py", line 329, in pretrain_models_optimized
    for X_batch, targets_batch in pbar:
                                  ^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\dataloader.py", line 734, in __next__
    data = self._next_data()
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\dataloader.py", line 1516, in _next_data
    return self._process_data(data, worker_id)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\dataloader.py", line 1551, in _process_data
    data.reraise()
    ~~~~~~~~~~~~^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\_utils.py", line 769, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 5.
Original Traceback (most recent call last):
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ~~~~~~~~~~~~~~~^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 212, in collate
    collate(samples, collate_fn_map=collate_fn_map)
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 155, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 270, in collate_tensor_fn
    storage = elem._typed_storage()._new_shared(numel, device=elem.device)
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\storage.py", line 1203, in _new_shared
    untyped_storage = torch.UntypedStorage._new_shared(
        size * self._element_size(), device=device
    )
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\storage.py", line 414, in _new_shared
    return cls._new_using_filename_cpu(size)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
RuntimeError: Couldn't open shared file mapping: <torch_33852_2861069063_5082>, error code: <1455>

2025-08-18 09:31:43 - root - ERROR - 实验执行失败: Caught RuntimeError in DataLoader worker process 5.
Original Traceback (most recent call last):
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ~~~~~~~~~~~~~~~^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 212, in collate
    collate(samples, collate_fn_map=collate_fn_map)
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 155, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 270, in collate_tensor_fn
    storage = elem._typed_storage()._new_shared(numel, device=elem.device)
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\storage.py", line 1203, in _new_shared
    untyped_storage = torch.UntypedStorage._new_shared(
        size * self._element_size(), device=device
    )
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\storage.py", line 414, in _new_shared
    return cls._new_using_filename_cpu(size)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
RuntimeError: Couldn't open shared file mapping: <torch_33852_2861069063_5082>, error code: <1455>

2025-08-18 09:31:43 - root - ERROR - 详细错误信息:
Traceback (most recent call last):
  File "E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP\main.py", line 81, in main
    experiment.run()
    ~~~~~~~~~~~~~~^^
  File "E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP\libs\modes\global_mode_optimized.py", line 715, in run
    self.pretrain_models_optimized()
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "E:\MyDocument\Codes_notnut\_notpad\IEDA\RealdataEXP\libs\modes\global_mode_optimized.py", line 329, in pretrain_models_optimized
    for X_batch, targets_batch in pbar:
                                  ^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\tqdm\std.py", line 1181, in __iter__
    for obj in iterable:
               ^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\dataloader.py", line 734, in __next__
    data = self._next_data()
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\dataloader.py", line 1516, in _next_data
    return self._process_data(data, worker_id)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\dataloader.py", line 1551, in _process_data
    data.reraise()
    ~~~~~~~~~~~~^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\_utils.py", line 769, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 5.
Original Traceback (most recent call last):
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 55, in fetch
    return self.collate_fn(data)
           ~~~~~~~~~~~~~~~^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 398, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 212, in collate
    collate(samples, collate_fn_map=collate_fn_map)
    ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 155, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\utils\data\_utils\collate.py", line 270, in collate_tensor_fn
    storage = elem._typed_storage()._new_shared(numel, device=elem.device)
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\storage.py", line 1203, in _new_shared
    untyped_storage = torch.UntypedStorage._new_shared(
        size * self._element_size(), device=device
    )
  File "E:\miniconda\envs\intelxpu\Lib\site-packages\torch\storage.py", line 414, in _new_shared
    return cls._new_using_filename_cpu(size)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
RuntimeError: Couldn't open shared file mapping: <torch_33852_2861069063_5082>, error code: <1455>

