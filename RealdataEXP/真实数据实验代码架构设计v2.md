## 1. 目标与设计原则 

本项目旨在复现并扩展论文 `Tackling Interference Induced by Data Training Loops` 中的实验，使用 `KuaiRand` 真实数据集进行数值模拟。

**核心模拟逻辑**：
模拟一个随时间演进的推荐系统。用户不断进入系统，系统根据当前的推荐模型（实验组或对照组）为其推荐视频。用户的真实反馈（是否点击、播放多久）被记录下来，并被添加到**一个动态增长的历史数据池**中。模型会定期在这个累积的数据池上进行重新训练，从而形成一个闭环。

**设计原则保持不变**：模块化、可配置性、可扩展性、PyTorch优先。

---

## 2. 项目文件树结构

文件树结构保持不变，它依然能够很好地支持更新后的动态模拟逻辑。

```plaintext
/KuaiRand_Interference_Exp/
├── configs/
│   └── experiment_config.yaml      # 统一管理所有实验参数
│
├── data/                           # 存放KuaiRand数据集
│   └── ...
│
├── notebooks/
│   └── 1_data_exploration.ipynb    # 数据探索与可视化
│   └── 2_results_analysis.ipynb    # 实验结果分析与绘图
│
├── src/                            # 核心源代码目录
│   ├── __init__.py
│   ├── data_manager.py             # 负责管理全部数据和动态历史数据
│   ├── models.py                   # PyTorch模型定义 (预测模型, 权重模型) # 要加入Wide模型
│   ├── trainers.py                 # 核心训练逻辑
│   ├── recommender.py              # 模拟推荐与排序逻辑
│   ├── utils.py                    # 工具函数 (日志, 保存, 指标计算)
│   └── main.py                     # 实验主入口，实现动态模拟循环
│
├── results/                        # 保存所有实验产出
│   ├── logs/                       # 训练日志文件
│   ├── checkpoints/                # 模型权重文件
│   └── plots/                      # 生成的图表
│
├── requirements.txt                # 项目依赖库
└── README.md                       # 项目说明文档
````

-----

## 3\. 核心模块代码架构详解 

### 3.1. `configs/experiment_config.yaml` - 实验配置 

增加了模拟循环所需的参数。

```yaml
# 路径配置
dataset_name: "Pure" # or "1K"
data_path: "./data/"
results_path: "./results/"

# 实验设置
experiment_method: "weighted" # 'weighted', 'pooling', 'splitting', 'snapshot'
repetitions: 100
p_treatment: 0.5

# (新增) 动态模拟循环参数
total_simulation_steps: 100000 # 模拟的总用户交互次数
candidate_pool_size: 100       # 为每个用户提供的候选视频数量
initial_dataset_size: 5000     # 用于模型初始化的数据量
train_every_n_steps: 1000      # 每隔多少次交互就重新训练一次模型

# 模型超参数 (与之前相同)
prediction_model:
  input_dim: 50 
  hidden_dims: [128, 64]
  output_dim: 2

# ... 其他参数 ...
```

### 3.2. `src/data_manager.py` - 数据管理器 

**职责**：这是本次更新的核心。它不再是一个简单的`Dataset`，而是一个管理者，负责：

1.  加载并持有 **“上帝视角”** 的全部数据。
2.  提供模拟所需的数据流，如按时间顺序的用户流。
3.  维护一个 **动态增长的、已被观察到的历史数据集**（“已推送数据集”）。

<!-- end list -->

```python
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader

class DataManager:
    def __init__(self, config):
        """
        1. 加载所有CSV文件并合并成一个大的 "master_df" DataFrame。
           这个DataFrame包含了所有可能发生的 user-video 交互及其真实结果。
        2. 对特征进行预处理和数值化。
        3. 按照 time_ms 对 master_df 进行排序，以模拟时间流。
        """
        self.master_df = ...
        self.user_features = ...
        self.video_features = ...

    def get_simulation_stream(self, num_steps):
        """返回一个生成器，用于模拟 'num_steps' 次用户-视频交互"""
        # 从排序后的 master_df 中逐行产生数据
        for _, interaction in self.master_df.head(num_steps).iterrows():
            yield interaction

    def get_candidate_videos(self, user_id, size):
        """为指定用户随机选择一个候选视频池"""
        # ... (从所有视频中随机采样)

    def create_interaction_features(self, user_id, video_ids):
        """为用户和一组视频创建交互特征矩阵 X"""
        # ... (合并用户特征和视频特征)

    def get_ground_truth_label(self, user_id, video_id):
        """从 master_df 中查找特定交互的真实标签 Y"""
        # ... (返回 is_click 和 play_time_ms)

class HistoryBuffer(Dataset):
    """一个动态的数据集，用于存储已观察到的交互历史 (X, Y, Z)"""
    def __init__(self):
        self.buffer = []

    def add(self, x, y, z):
        self.buffer.append((x, y, z))

    def __len__(self):
        return len(self.buffer)

    def __getitem__(self, idx):
        return self.buffer[idx]
```

### 3.3. `src/models.py` - PyTorch模型定义 

**职责**：保持不变，但明确了损失函数。

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class PredictionModel(nn.Module):
    # ... (结构同前) ...
    def forward(self, x):
        # ... (同前) ...
        return pred_click_logit, pred_play_time # 返回logit和回归值

    def loss_function(self, pred_click_logit, pred_play_time, Y, weights=None):
        """计算组合损失"""
        # 点击率预测使用带权重的BCE Loss
        loss_click = F.binary_cross_entropy_with_logits(
            pred_click_logit, Y[:, 0], weight=weights
        )
        # 播放时长预测使用带权重的MSE Loss
        loss_time = F.mse_loss(pred_play_time, Y[:, 1], reduction='none')
        if weights is not None:
            loss_time = (loss_time * weights).mean()
        else:
            loss_time = loss_time.mean()
        
        return loss_click + loss_time # 可根据需要调整损失的权重

# WeightingModel 保持不变
```

### 3.4. `src/trainers.py` - 核心训练逻辑 

**职责**：训练逻辑本身不变，但训练的触发方式和数据源改变了。

```python
class WeightedTrainer(BaseTrainer):
    # ... (初始化模型和优化器) ...
    
    def train_on_history(self, history_loader: DataLoader):
        """在整个历史数据上进行训练"""
        for X, Y, Z in history_loader:
            X, Y, Z = X.to(self.device), Y.to(self.device), Z.to(self.device)
            
            # 1. 训练权重模型 G (与之前类似)
            # ...
            
            # 2. 计算权重 (与之前类似)
            # ...
            
            # 3. 加权训练预测模型 M_T 和 M_C
            self.model_T.train()
            self.optimizer_T.zero_grad()
            pred_click_t, pred_time_t = self.model_T(X)
            loss_t = self.model_T.loss_function(pred_click_t, pred_time_t, Y, weights=weight_t)
            loss_t.backward()
            self.optimizer_T.step()
            
            # ... (类似地更新 M_C)
```

### 3.5. `src/main.py` - 实验主入口 

**职责**：实现全新的、基于时间步的动态模拟循环。

```python
import yaml
from data_manager import DataManager, HistoryBuffer
from trainers import WeightedTrainer, ...
from recommender import Recommender
from torch.utils.data import DataLoader

def run_experiment(config):
    # 1. 初始化
    logger = setup_logging(config)
    data_manager = DataManager(config)
    history_buffer = HistoryBuffer()

    # 2. 模型初始化 (使用一小部分初始数据)
    # ... (获取初始数据，训练一个初始模型 snapshot_model)
    
    # 3. 根据配置，创建实验所需的训练器和推荐器
    trainer = WeightedTrainer(config, initial_model_state=snapshot_model.state_dict())
    recommender_C = Recommender(trainer.model_C, config['recommender']['control_alpha'])
    recommender_T = Recommender(trainer.model_T, config['recommender']['treatment_alpha'])

    # 4. 动态模拟主循环
    for step, interaction in enumerate(data_manager.get_simulation_stream(config['total_simulation_steps'])):
        user_id = interaction['user_id']
        
        # a. 分配实验组/对照组
        Z = torch.bernoulli(torch.tensor(config['p_treatment'])).item()
        
        # b. 为用户创建候选视频的特征
        candidate_video_ids = data_manager.get_candidate_videos(user_id, config['candidate_pool_size'])
        interaction_features = data_manager.create_interaction_features(user_id, candidate_video_ids)
        
        # c. 根据分组进行推荐
        if Z == 1: # 实验组
            recommended_idx = recommender_T.recommend(interaction_features)
        else: # 对照组
            recommended_idx = recommender_C.recommend(interaction_features)
            
        # d. 获取被推荐项的特征 (X) 和真实反馈 (Y)
        recommended_video_id = candidate_video_ids[recommended_idx]
        X_observed = interaction_features[recommended_idx]
        Y_observed = data_manager.get_ground_truth_label(user_id, recommended_video_id)
        
        # e. 将观察到的 (X, Y, Z) 存入历史缓冲池
        history_buffer.add(X_observed, Y_observed, torch.tensor(Z))
        
        # f. 定期在累积的历史数据上重新训练模型
        if (step + 1) % config['train_every_n_steps'] == 0:
            logger.info(f"Step {step+1}: Retraining models on {len(history_buffer)} samples...")
            history_loader = DataLoader(history_buffer, batch_size=config['batch_size'], shuffle=True)
            trainer.train_on_history(history_loader)

    # 5. 保存最终结果和分析
    # ...
```

-----

## 4\. 后续步骤建议 

1.  **核心实现 `data_manager.py`**：这是启动项目的第一步。重点是高效地加载和查询`master_df`，并实现一个灵活的`create_interaction_features`函数。
2.  **构建 `main.py` 的模拟循环**：这是新的架构核心。确保用户流、推荐、反馈、存储和再训练的逻辑正确无误地衔接。
3.  **实现 `trainers.py`**：在新的`train_on_history`框架下，实现四种不同的训练策略。
4.  **迭代与分析**：从简单的`DataPooling`或`Snapshot`方法开始测试，确保整个模拟流程可以无误运行。然后实现并调试核心的`WeightedTrainer`。最后，在`notebooks/2_results_analysis.ipynb`中进行深入的统计分析。