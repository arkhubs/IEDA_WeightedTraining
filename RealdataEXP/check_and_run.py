#!/usr/bin/env python3
"""
ç¯å¢ƒæ£€æµ‹å¹¶è¿è¡Œå®éªŒçš„Pythonè„šæœ¬
æä¾›æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œç”¨æˆ·äº¤äº’
"""

import os
import sys
import subprocess
import torch
import time

def print_banner(title):
    """æ‰“å°æ ‡é¢˜æ¨ªå¹…"""
    print("=" * 60)
    print(f" {title}")
    print("=" * 60)

def check_gpu_availability():
    """æ£€æŸ¥GPUå¯ç”¨æ€§"""
    print("ğŸ” æ£€æŸ¥GPUè®¾å¤‡...")
    
    # æ£€æŸ¥nvidia-smiå‘½ä»¤
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("âœ… nvidia-smi å¯ç”¨")
            # æ˜¾ç¤ºGPUä¿¡æ¯çš„ç®€åŒ–ç‰ˆæœ¬
            lines = result.stdout.split('\n')
            for line in lines:
                if 'GeForce' in line or 'Quadro' in line or 'Tesla' in line or 'RTX' in line or 'GTX' in line or 'A30' in line or 'V100' in line:
                    print(f"   GPU: {line.strip()}")
            return True
        else:
            print("âŒ nvidia-smi å‘½ä»¤å¤±è´¥")
            return False
    except (subprocess.TimeoutExpired, FileNotFoundError):
        print("âŒ nvidia-smi ä¸å¯ç”¨")
        return False

def check_cuda_toolkit():
    """æ£€æŸ¥CUDAå·¥å…·åŒ…"""
    print("\nğŸ” æ£€æŸ¥CUDAå·¥å…·åŒ…...")
    
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            # æå–CUDAç‰ˆæœ¬ä¿¡æ¯
            for line in result.stdout.split('\n'):
                if 'release' in line:
                    print(f"âœ… CUDAç¼–è¯‘å™¨: {line.strip()}")
            return True
        else:
            print("âš ï¸ CUDAç¼–è¯‘å™¨ä¸å¯ç”¨")
            return False
    except (subprocess.TimeoutExpired, FileNotFoundError):
        print("âš ï¸ nvcc å‘½ä»¤ä¸å¯ç”¨")
        return False

def check_pytorch_cuda():
    """æ£€æŸ¥PyTorch CUDAæ”¯æŒ"""
    print("\nğŸ” æ£€æŸ¥PyTorch CUDAæ”¯æŒ...")
    
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    if torch.cuda.is_available():
        print("âœ… PyTorchæ£€æµ‹åˆ°CUDAæ”¯æŒ")
        print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            gpu_name = torch.cuda.get_device_name(i)
            print(f"   GPU {i}: {gpu_name}")
        
        # ç®€å•çš„GPUè®¡ç®—æµ‹è¯•
        try:
            device = torch.device('cuda')
            x = torch.randn(100, 100, device=device)
            y = torch.randn(100, 100, device=device)
            z = torch.mm(x, y)
            print("âœ… GPUè®¡ç®—æµ‹è¯•é€šè¿‡")
            
            # æ¸…ç†
            del x, y, z
            torch.cuda.empty_cache()
            return True
        except Exception as e:
            print(f"âŒ GPUè®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
            return False
    else:
        print("âŒ PyTorchæ£€æµ‹ä¸åˆ°CUDAæ”¯æŒ")
        return False

def check_project_setup():
    """æ£€æŸ¥é¡¹ç›®é…ç½®"""
    print("\nğŸ” æ£€æŸ¥é¡¹ç›®é…ç½®...")
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    config_file = "configs/experiment.yaml"
    if os.path.exists(config_file):
        print(f"âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_file}")
    else:
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        return False
    
    # æ£€æŸ¥ä¸»ç¨‹åº
    main_file = "main.py"
    if os.path.exists(main_file):
        print(f"âœ… ä¸»ç¨‹åºå­˜åœ¨: {main_file}")
    else:
        print(f"âŒ ä¸»ç¨‹åºä¸å­˜åœ¨: {main_file}")
        return False
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = "data/KuaiRand/Pure"
    if os.path.exists(data_dir):
        print(f"âœ… æ•°æ®ç›®å½•å­˜åœ¨: {data_dir}")
        files = os.listdir(data_dir)
        csv_files = [f for f in files if f.endswith('.csv')]
        print(f"   æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ•°æ®æ–‡ä»¶")
    else:
        print(f"âš ï¸ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("   æ³¨æ„ï¼šå¦‚æœæ˜¯é¦–æ¬¡è¿è¡Œï¼Œè¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨")
    
    return True

def wait_for_user_confirmation():
    """ç­‰å¾…ç”¨æˆ·ç¡®è®¤"""
    print("\n" + "=" * 60)
    print("ğŸš€ å‡†å¤‡å¼€å§‹å®éªŒ")
    print("=" * 60)
    print("æ‰€æœ‰ç¯å¢ƒæ£€æŸ¥å·²å®Œæˆï¼")
    print()
    print("å®éªŒå°†ä½¿ç”¨ä»¥ä¸‹é…ç½®:")
    print("  - é…ç½®æ–‡ä»¶: configs/experiment.yaml")
    print("  - å®éªŒæ¨¡å¼: global")
    print("  - è®¾å¤‡: è‡ªåŠ¨é€‰æ‹© (GPUä¼˜å…ˆ)")
    print()
    
    try:
        input("æŒ‰å›è½¦é”®å¼€å§‹å®éªŒï¼Œæˆ–æŒ‰Ctrl+Cé€€å‡º...")
    except KeyboardInterrupt:
        print("\nç”¨æˆ·å–æ¶ˆå®éªŒ")
        sys.exit(0)

def run_experiment():
    """è¿è¡Œå®éªŒ"""
    print("\n" + "=" * 60)
    print("ğŸ”¥ å¼€å§‹è¿è¡Œå®éªŒ")
    print("=" * 60)
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['CUDA_VISIBLE_DEVICES'] = '0'
    os.environ['PYTHONPATH'] = os.environ.get('PYTHONPATH', '') + ':' + os.getcwd()
    
    try:
        # è¿è¡Œä¸»ç¨‹åº
        result = subprocess.run([
            sys.executable, 'main.py', 
            '--config', 'configs/experiment.yaml', 
            '--mode', 'global'
        ], check=True)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ å®éªŒæˆåŠŸå®Œæˆï¼")
        print("=" * 60)
        
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ å®éªŒè¿è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {e.returncode}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­å®éªŒ")
        sys.exit(0)

def main():
    """ä¸»å‡½æ•°"""
    print_banner("RealdataEXP GPUç¯å¢ƒæ£€æµ‹ä¸å®éªŒå¯åŠ¨")
    print(f"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ä¸»æœº: {os.uname().nodename}")
    print(f"å·¥ä½œç›®å½•: {os.getcwd()}")
    
    # ç¯å¢ƒæ£€æµ‹æ­¥éª¤
    checks = [
        ("GPUè®¾å¤‡", check_gpu_availability),
        ("CUDAå·¥å…·åŒ…", check_cuda_toolkit), 
        ("PyTorch CUDA", check_pytorch_cuda),
        ("é¡¹ç›®è®¾ç½®", check_project_setup)
    ]
    
    failed_checks = []
    
    for check_name, check_func in checks:
        print_banner(f"æ£€æŸ¥: {check_name}")
        try:
            if not check_func():
                failed_checks.append(check_name)
        except Exception as e:
            print(f"âŒ æ£€æŸ¥ {check_name} æ—¶å‡ºé”™: {e}")
            failed_checks.append(check_name)
    
    # æ€»ç»“æ£€æµ‹ç»“æœ
    print_banner("æ£€æµ‹ç»“æœæ€»ç»“")
    if failed_checks:
        print("âŒ ä»¥ä¸‹æ£€æŸ¥å¤±è´¥:")
        for check in failed_checks:
            print(f"   - {check}")
        
        # åªè¦PyTorch CUDAå¯ç”¨å°±å¯ä»¥ç»§ç»­
        if "PyTorch CUDA" not in failed_checks:
            print("\nâš ï¸ å°½ç®¡æŸäº›æ£€æŸ¥å¤±è´¥ï¼Œä½†PyTorch CUDAå¯ç”¨")
            print("å®éªŒä»å¯èƒ½æ­£å¸¸è¿è¡Œ")
        else:
            print("\nğŸ›‘ å…³é”®æ£€æŸ¥å¤±è´¥ï¼Œå»ºè®®ä¿®å¤åå†è¿è¡Œå®éªŒ")
            choice = input("æ˜¯å¦ä»è¦ç»§ç»­? (y/N): ").strip().lower()
            if choice != 'y':
                print("é€€å‡ºç¨‹åº")
                sys.exit(1)
    else:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
    
    # ç­‰å¾…ç”¨æˆ·ç¡®è®¤å¹¶è¿è¡Œå®éªŒ
    wait_for_user_confirmation()
    run_experiment()

if __name__ == "__main__":
    main()