## 关于数据
- 已有数据：用户对视频的互动行为，顺序数据
	- 在最小的数据集内，一个用户对应几十或上百个视频
	- 数据结构：从互动行为表出发，需要 feature 数据时，根据 user_id 和 video_id 去 feature 表里面查找
- $Y$ 的候选：
	- is_click / is_like / is_follow / is_comment / is_hate
	- play_time_ms / long_view / `play_time_ms➗duration_ms`
- 可用的 $X$：
	- 多多益善
- 数据集自带 A/B Test，前一段时间为正常推送（A）；后一段时间插入了随机推送（后一段时间整体视为B）（占比很高）
	- 前后两段时间为同一批用户，<font color="#ff0000">这是否存在时间上的干扰？</font>
	- <font color="#ff0000">另一种用法？：所有正常推送的视频视为 A；所有随机推送的视频视为 B</font>
- 数据集生成过程中是否存在本文所说的干扰？
	- 应当是有的，因为存在推荐算法推荐视频的过程

---

## 实验方法与目标
- 目标：训练出预测用户行为的模型 $M_\theta$，用来估计 $GTE$
	- 使用加权训练、数据池化、快照、数据分割四种方法分别训练，比较最终的 log 损失、预测方差、用它们估计的 GTE 的箱线图<font color="#ff0000">（这里具体如何比较需要老师指导）</font>
	- 在 pure、1K、27K 三个大小上进行实验，每个重复实验 $B$ 次
	- 编写代码先从最小的 pure 开始尝试

- 以下分别是每种方法的 $M$ 的训练过程
1. 加权训练 **（本文方法）**
	- 首先初始化分类器 $G_{\theta_W}: \mathbb{R}^d \rightarrow [0,1]$ 用于估计 $E [Z|X_E]$；初始化实验组模型 $M_{\theta_T}$ 和控制组模型 $M_{\theta_C}$
	- 第 $t$ 个 epoch 纳入 $n_t$ 个用户 ($n_t < n$) ，$t$ 初值为 1
		- 对 $n_t$ 个用户随机分组（参数为 p 的 Bernoulli 分布产生 $Z$）
		- 他们的 $X$ 作为 feature，$Z$ 作为 label，优化 $G_{\theta_W}$<font color="#ff0000">（原本是先优化</font> $M$<font color="#ff0000">，这里我改了一下）</font>
			- 神经网络 or SVM or 随机森林
		- 根据 `user_id` 和 `Z`，去数据集中查找所有满足条件的 `Y`
			- 这里有两种处理办法：
				1. 使用所有满足条件的 Y（被推给该用户的所有控制组/实验组视频）
				2. 进行随机抽样，取其中 $m$ 个
		- 计算权重：
		$$
			W_{T,i,t} = \frac{G_{\theta_W}(X_{i,t})}{p}, \quad W_{C,i,t} = \frac{1-G_{\theta_W}(X_{i,t})}{1-p}.
		$$
		- $X$ 作为 feature，$Y$ 作为 label，由 $W_T \mathcal{D}_E \stackrel{d}{=} \mathcal{D}_T$ 更新实验组模型；由 $W_C \mathcal{D}_E \stackrel{d}{=} \mathcal{D}_C$ 更新控制组模型
		- t=t+1
2. 数据池化：每次优化使用这个时间点 $t$ 的所有 X 和 Y 
3. 快照：事先拟合好 M，再开始实验，相当于脱离 Test 直接拟合所有 X 和 Y
4. 数据分割：每次优化实验组仅使用 $Z=1$ 的 X 和 Y；控制组仅使用 $Z=0$ 的 X 和 Y

- 然后进行各种指标的对比

1. 推荐算法 model：Wide & Deep Learning for Recommender Systems
  1. https://arxiv.org/abs/2205.09809
  2. deep learning recommendation model
  3. 先用 LM 代替
2. framework modelize （模块化）
3. 确定 X 和 Y，写出 data 的状况
4. 定期分享代码（可以考虑 git）
5. 用英文写 report
6. 100 个推一个（已有的）
7. GTE 计算：用我们自己的 A/B Test，
8. [x] 办 visa 卡；保险时间往后挪（夏令营时间确定后）



## ToDo 20250721

- [ ] Wide模型先不实装

- [x] 调整模型特征和标签

- [x] 调整模型网络结构

- [ ] 播放时长是0是否可以替代掉点击率这个标签

- [x] 跑通demo
  - [x] 环境配置
  - [x] 对于NaN处理：
    - [x] 数值变量采用预测模型；（或者可以额外增加一个特征，表示该值是否是由缺失值预测而来的；这里先采用均值填充，以后再改；
    - [x] 如果是分类变量，直接将缺失值作为一个独立类别`Missing`
    - [ ] 改进计划
  - [x] weight预测出现预测值全为极端的情况
    - [x] 加batch norm
    - [ ] 如需更细致的分布控制可考虑 clip/log1p 等操作
  
- [x] 创建git
  - [x] 在服务器上下载数据集
  - [x] 在服务器上运行
  - [ ] 开免登录
  
- [x] 安排meeting时间

- [x] 调参（费时费力）
  - [x] MSE_play_time始终比较大
    - [x] 排查是否是本来scale就大
      - [x] 是的
  - [x] 画图发现不正常![exp_results_plot](./assets/exp_results_plot.png)
  - [x] loss_click + loss_time的比例是否正常，会否其中一个数值占据绝对主导
    - [x] 分开训练
  - [x] 测AUC 0.75足够
  - [ ] 模型变小
    - [x] 3层，8，16，32
    - [ ] 特征数量减少
  - [x] 测试集
  - [x] 另外你这里测试集和测试集是怎么划分的，每次抽取范围是怎么样的；还有预训练的5000个数据点在代码的哪个部分实现？
  
- [ ] 尝试不同指标组合

- [ ] cuda支持问题

  - [x] 发邮件

- [x] 预训练有在进行吗？输出一下结果

- [x] 修复相对路径问题

  - [x] >
    > 帮我解决以下问题：
    >
    > 1. 现在代码中绝对路径和相对路径混用，我希望你彻底修复有序，最多仅在config文件中指定base目录，之后任何时候cd到base目录之后，运行脚本、调用数据集都不会出现路径问题。
    >
    >    文件树如下：IEDA_WeightedTraining/
    >      ├── configs/
    >      │     └── experiment_config.yaml
    >      ├── results/
    >      │     ├── plot_exp_results.py
    >      │     └── test/...
    >      ├── src/
    >      │     ├── main.py
    >      │     ├── data_manager.py
    >      │     ├── models.py
    >      │     ├── trainers.py
    >      │     ├── recommender.py
    >      │     └── utils.py
    >    KuaiRand/
    >      ├── 1K/
    >      ├── 27K/
    >      │     └── data/
    >      │           ├── log_standard_4_08_to_4_21_27k_part1.csv
    >      │           ├── log_standard_4_08_to_4_21_27k_part2.csv
    >      │           ├── log_standard_4_22_to_5_08_27k_part1.csv
    >      │           ├── log_standard_4_22_to_5_08_27k_part2.csv
    >      │           ├── log_random_4_22_to_5_08_27k.csv
    >      │           ├── user_features_27k.csv
    >      │           ├── video_features_basic_27k.csv
    >      │           ├── video_features_statistic_27k_part1.csv
    >      │           ├── video_features_statistic_27k_part2.csv
    >      │           └── video_features_statistic_27k_part3.csv
    >      └── Pure/
    >
    > 2. 27K数据集加载非常慢，而且以下运行日志显示卡在最后一步3个小时之后才出现报错信息，请寻找问题原因并修复：
    >
    >    [zhixuanhu@login2 IEDA_WeightedTraining]$ python3 IEDA_WeightedTraining/src/main.py
    >    [DEBUG] Pattern: KuaiRand/27K/data/log_standard_4_08_to_4_21_27k_part*.csv
    >    [DEBUG] Matched files: ['KuaiRand/27K/data/log_standard_4_08_to_4_21_27k_part1.csv', 'KuaiRand/27K/data/log_standard_4_08_to_4_21_27k_part2.csv']
    >    [DEBUG] Loading log file: KuaiRand/27K/data/log_standard_4_08_to_4_21_27k_part1.csv
    >    [DEBUG] Loading log file: KuaiRand/27K/data/log_standard_4_08_to_4_21_27k_part2.csv
    >    [DEBUG] Pattern: KuaiRand/27K/data/log_standard_4_22_to_5_08_27k_part*.csv
    >    [DEBUG] Matched files: ['KuaiRand/27K/data/log_standard_4_22_to_5_08_27k_part1.csv', 'KuaiRand/27K/data/log_standard_4_22_to_5_08_27k_part2.csv']
    >    [DEBUG] Loading log file: KuaiRand/27K/data/log_standard_4_22_to_5_08_27k_part1.csv
    >    [DEBUG] Loading log file: KuaiRand/27K/data/log_standard_4_22_to_5_08_27k_part2.csv
    >    [DEBUG] Pattern: KuaiRand/27K/data/log_random_4_22_to_5_08_27k_part*.csv
    >    [DEBUG] Matched files: []
    >    [DEBUG] Check single file: KuaiRand/27K/data/log_random_4_22_to_5_08_27k.csv, exists=True
    >    [DEBUG] Loading log file: KuaiRand/27K/data/log_random_4_22_to_5_08_27k.csv
    >    [DEBUG] logs length: 5
    >    [Device] Available devices: ['cpu'], selected: cpu
    >
    >      File "/home/zhixuanhu/.local/lib/python3.9/site-packages/pandas/core/generic.py", line 6331, in __setattr__
    >        object.__getattribute__(self, name)
    >      File "/home/zhixuanhu/.local/lib/python3.9/site-packages/pandas/core/series.py", line 782, in name
    >        return self._name
    >      File "/home/zhixuanhu/.local/lib/python3.9/site-packages/pandas/core/generic.py", line 6318, in __getattr__
    >        return object.__getattribute__(self, name)
    >    AttributeError: 'Series' object has no attribute '_name'
    >
    >    During handling of the above exception, another exception occurred:
    >
    >    Traceback (most recent call last):
    >      File "/home/zhixuanhu/IEDA_WeightedTraining/IEDA_WeightedTraining/src/main.py", line 253, in <module>
    >        run_experiment(config)
    >      File "/home/zhixuanhu/IEDA_WeightedTraining/IEDA_WeightedTraining/src/main.py", line 114, in run_experiment
    >        pretrain_weights_path = pretrain_models(config, logger, data_manager, device)
    >      File "/home/zhixuanhu/IEDA_WeightedTraining/IEDA_WeightedTraining/src/main.py", line 36, in pretrain_models
    >        all_interactions = list(data_manager.get_all_interactions())
    >      File "/home/zhixuanhu/IEDA_WeightedTraining/IEDA_WeightedTraining/src/data_manager.py", line 74, in get_all_interactions
    >        for _, interaction in self.master_df.iterrows():
    >      File "/home/zhixuanhu/.local/lib/python3.9/site-packages/pandas/core/frame.py", line 1559, in iterrows
    >        s = klass(v, index=columns, name=k).__finalize__(self)
    >      File "/home/zhixuanhu/.local/lib/python3.9/site-packages/pandas/core/series.py", line 593, in __init__
    >        self.name = name
    >      File "/home/zhixuanhu/.local/lib/python3.9/site-packages/pandas/core/generic.py", line 6331, in __setattr__
    >        object.__getattribute__(self, name)
    >    KeyboardInterrupt
    >
    > 3. 不需要的feature也被同时加载，请你想办法优化，比如config增加一个选项，想办法load数据集（尤其是27K这种20GB的）后，缓存（放在KuaiRand目录下），加快下次加载
    >
    > 4. 完整顺利运行一次之后，你可能会看到结果不太好，AUC无法超过0.6，logMAE越来越大，检查损失函数中loss_click + loss_time的比例是否正常，会否其中一个数值占据绝对主导，如果是，尝试调整；如果还是不行，可能是两个预测指标相互干扰训练，考虑彻底将click预测模型和playtime预测模型拆开成两个，这在config文件中又要如何体现
    >
    > 5. 再次实验，如果还是不好，也有可能是特征数量102过多问题，是否需要减少一些，你先检索所有特征，然后做实验探究
    >
    > 6. 思考别的可能原因导致我训练结果不好

 - [x] > 帮我诊断：现在的问题是，预训练环节的step3总是卡住很久，而且数据集规模越大卡住越久；之后我换到了最小的数据集，结果还是卡住了，具体查看log：
   >
   > 2025-07-30 19:42:39,518 INFO Using device: cpu
   >
   > 2025-07-30 19:42:39,519 INFO [Pretrain] 开始预训练，随机选择 5000 个交互
   >
   > 2025-07-30 19:55:36,890 INFO Using device: cpu
   >
   > 2025-07-30 19:55:36,890 INFO [Pretrain] 开始预训练，随机选择 5000 个交互
   >
   > 2025-07-30 19:55:36,890 INFO [Pretrain] Step 1: 获取所有交互样本 ...
   >
   > 2025-07-30 19:58:16,146 INFO [Pretrain] Step 1: 获取所有交互样本完成，数量: 11756073
   >
   > 2025-07-30 19:58:16,146 INFO [Pretrain] Step 2: 随机采样交互 ...
   >
   > 2025-07-30 19:58:20,857 INFO [Pretrain] Step 2: 随机采样完成，采样数量: 5000
   >
   > 2025-07-30 19:58:20,857 INFO [Pretrain] Step 3: 构建预训练数据 ...
   >
   > 2025-07-30 19:58:20,857 INFO [Pretrain] Step 3: 构建中 0/5000 ...
   >
   > 2025-07-30 20:02:50,362 INFO [Pretrain] Step 3: 构建中 100/5000 ...
   >
   > 2025-07-30 20:07:12,224 INFO [Pretrain] Step 3: 构建中 200/5000 ...
   >
   > 2025-07-30 20:11:20,221 INFO Using device: cpu
   >
   > 2025-07-30 20:11:20,221 INFO [Pretrain] 开始预训练，随机选择 5000 个交互
   >
   > 2025-07-30 20:11:20,221 INFO [Pretrain] Step 1: 获取所有交互样本 ...
   >
   > 2025-07-30 20:14:04,562 INFO [Pretrain] Step 1: 获取所有交互样本完成，数量: 11756073
   >
   > 2025-07-30 20:14:04,563 INFO [Pretrain] Step 2: 随机采样交互 ...
   >
   > 2025-07-30 20:14:09,123 INFO [Pretrain] Step 2: 随机采样完成，采样数量: 5000
   >
   > 2025-07-30 20:14:09,123 INFO [Pretrain] Step 3: 批量构建预训练数据 ...
   >
   > 2025-07-30 20:14:09,125 INFO [Pretrain] Step 3: 批量生成特征 ...
   >
   > 2025-07-30 20:16:16,442 INFO Using device: cpu
   >
   > 2025-07-30 20:16:16,442 INFO [Pretrain] 开始预训练，随机选择 5000 个交互
   >
   > 2025-07-30 20:16:16,442 INFO [Pretrain] Step 1: 获取所有交互样本 ...
   >
   > 2025-07-30 20:18:56,156 INFO [Pretrain] Step 1: 获取所有交互样本完成，数量: 11756073
   >
   > 2025-07-30 20:18:56,157 INFO [Pretrain] Step 2: 随机采样交互 ...
   >
   > 2025-07-30 20:19:00,702 INFO [Pretrain] Step 2: 随机采样完成，采样数量: 5000
   >
   > 2025-07-30 20:19:00,703 INFO [Pretrain] Step 3: 批量构建预训练数据 ...
   >
   > 2025-07-30 20:19:00,705 INFO [Pretrain] Step 3: 单条生成特征 ...
   >
   > 2025-07-30 20:19:00,705 INFO [Pretrain] Step 3: 特征生成进度 0/5000 ...
   >
   > 2025-07-30 20:34:58,053 INFO Using device: cpu
   >
   > 2025-07-30 20:34:58,053 INFO [Pretrain] 开始预训练，随机选择 5000 个交互
   >
   > 2025-07-30 20:34:58,053 INFO [Pretrain] Step 1: 获取所有交互样本 ...
   >
   > 2025-07-30 20:37:39,753 INFO [Pretrain] Step 1: 获取所有交互样本完成，数量: 11756073
   >
   > 2025-07-30 20:37:39,754 INFO [Pretrain] Step 2: 随机采样交互 ...
   >
   > 2025-07-30 20:37:44,292 INFO [Pretrain] Step 2: 随机采样完成，采样数量: 5000
   >
   > 2025-07-30 20:37:44,292 INFO [Pretrain] Step 3: 构建预训练数据 ...
   >
   > 2025-07-30 20:37:44,292 INFO [Pretrain] Step 3: 构建中 0/5000 ...
   >
   > 请你想办法优化-测试，先在pure上测试，正常了逐级往上扩大，直到解决问题
   >
   > 同时，我这里期望的epoch的意思是1000个step，每20个step评估一次，称为一个epoch，但现在显示的epoch总是1-5然后又复原，这是为何？并在此时询问我是否要修复
   >
   > 然后，要把实验组和对照组的预训练分开为2组独立进行；之后每个epoch的评测也要分开，画图程序相应调整

> 小样本运行
>
> sed -i 's/initial_dataset_size.* 5000/initial_dataset_size\": 50/g' IEDA_WeightedTraining/configs/experiment_config.yaml && python3 -m IEDA_WeightedTraining.src.main

![15bee03caef00fc584b934168a41d6c8](./assets/15bee03caef00fc584b934168a41d6c8.png)

- [ ] 训练逻辑需要大幅重构，参看以下说明；不再使用epoch的概念，每个step等价于1个epoch，n_user等价于batchsize

  - 我在config中指定了重复实验repetitions次，每次实验中：

    - 事先对**视频**划分训练集/测试集（mask），对**用户**划分处理组/对照组、比例决定于p_treatment和p_val，

    - 首先对照预测模型、处理预测模型、权重模型分别使用initial_dataset_size组交互数据和分组结果变量Z进行预训练

    - 然后每次实验迭代total_simulation_steps个step，每个step分别对n_user_T\n_user_C个处理组/对照组用户推介得分最好的1个视频，候选池为训练集内该用户看过、有交互数据的随机candidate_pool_size_train个视频（否则没有数据，不知道交互数据，若不足该数，则取允许的最大数），

    - 收集（即查找）被推介出去的那n_user_T\n_user_C个视频的交互数据，用于更新训练weight模型、model_C、model_T并记录训练loss等（不再用历史pool来训练，不再使用未被推介的数据来训练），后两者用于优化的损失函数是类似
  
      - $$
        \frac{1}{n_t} \sum_{i=1}^{n_t} W_{T,i,t} \ell(M_{\theta_T}(X_{i,t}), Y_{i,t}).
        $$

    - 更新完成后，在这n_user_T\n_user_C个用户的有交互数据的测试集视频中，为每个用户推介出得分最高的1个视频，用它们计算测试集的loss、auc等指标

    - log一次结果并画图
  
      
  
  - 参看：
  
  -  **算法 1：加权训练流程**：
        1. **输入**：处理分配概率 $p$，权重预测模型类 $\mathcal{G} = \{G_{\theta_W}: \mathbb{R}^d \rightarrow [0,1]\}$，机器学习模型类 $\mathcal{M}$，损失函数 $\ell(M(X), Y)$。
        2. **初始化**：实验模型 $M_{\theta_T}$ 和控制模型 $M_{\theta_C}$，均设置为当前生产模型。
        3. **循环**（时间 $t=1$ 至实验结束）：
            - 为 $n_t$ 个用户随机分配处理（概率 $p$）。
            - 根据分配推荐项目，收集数据 $(X_{i,t}, Y_{i,t}, Z_{i,t})$。
            - 计算权重：
    $$
    W_{T,i,t} = \frac{G_{\theta_W}(X_{i,t})}{p}, \quad W_{C,i,t} = \frac{1-G_{\theta_W}(X_{i,t})}{1-p}.
    $$
         - 更新实验模型 $M_{\theta_T}$，最小化加权损失：
    $$
    \frac{1}{n_t} \sum_{i=1}^{n_t} W_{T,i,t} \ell(M_{\theta_T}(X_{i,t}), Y_{i,t}).
    $$
         - 更新控制模型 $M_{\theta_C}$，类似最小化加权损失。
         - 更新权重模型 $G_{\theta_W}$，使用数据 $\{(X_{i,t}, Z_{i,t})\}$。
  
    4. **输出**：朴素估计器（PAGE10, Weighted Training）。
  
  - 另外，这些都在config中指定，不要放到main里面定义
  
  - log加上train和val分别涉及了多少个用户交互记录



- [ ] 问题：playtime的预测趋向于0，是否是因为大部分真实playtime都是0，那么我希望log记录的playtime不再计算全部的平均值和MSE，而是记录非0的playtime的平均相对误差（百分比那种），画图相应调整为（比例、布局也调整适应）：
  - 图块1：CTR AUC，包括train/val和treatment/control
  - 图块2：CTR XXloss，包括train/val和treatment/control
  - 图块3：playtime 平均相对误差（百分比），包括train/val和treatment/control
  - 图块4：playtime XXloss，包括train/val和treatment/control
  - 图块5：weightmodel AUC和Acurracy，包括train/val
  - 图块6：weightmoel XXloss，包括train/val



- [ ] 从log看，1K的预训练，生成每50个特征需要2分钟，直到正式开始预训练，用了50分钟，而预训练过程却在1秒内完成，这是代码的缺陷，还是不该如此先生成特征

  

- [ ] 下一步实验怎么做

  - 用训练好的模型（weight、T、C）预测测试集中的CTR、playtime，并根据playtime计算 long_view ，然后比较各种方法上述量的误差、方差
  - 如何比较各个模型对于GTE预测的效果好坏？
    - 真实的GTE无法知晓？
    - 使用实验日志（模拟的生产环境），计算估计的GTE
    - 比较方差？



> ### 一、 数据加载、处理与管理模块
>
> 这是实验的基础，负责准备和管理所需的数据。
>
> 1. **数据流**:
>    - 从数据集中提取 `user_id` 
>    - 根据 `user_id` 查找该用户所有**有过交互（看过）的视频列表（Video-list）**。
>    - 为了提高效率，设计了**缓存机制**，避免重复查找。
> 2. **数据集划分**:
>    - 仅将**用户**划分为**训练集（train-loader）和验证集（val-loader）**。
>    - 为训练数据增加两个标记位：
>      - `mask`: 原始标记，所有被分配到val的user看过的视频被标记为mask=1。
>      - `used`: **降权与隔离机制**。在仿真时，一个视频一旦被推荐给某个用户（无论是在GT还是GC流程中），其 `used` 标记置为1，之后**不会再次被推荐**。**重要的是，Treatment和Control两个仿真流程完全独立运行，不共享used**
> 3. **特征处理**:
>    1. 用户特征`user_active_degree`、视频基础特征`video_type`、`tag`是字符型类别变量，可以转化为若干个哑变量。
>    2. 视频基础特征`upload_dt`是日期格式，对于预测没有作用，不使用这个特征。
>    3. 各种id类变量不适合量化，也不需要，不作为特征使用。
>    4. 所有使用的特征都在config中声明式定义，只分两类（数值和分类），未声明的特征不用。
>    5. NA等缺失值作为一个新的类别；连续型变量则用0填充
>
> ### 二、 计算真实GTE的模块，称为global（GT与GC对称运行）
>
> 这是框架的核心。下面的流程会**独立运行两次**：一次所有user作为处理组使用处理组的alpha (vecalpha∗T)来计算GT，一次所有user作为对照组使用对照组的alpha (vecalpha∗C)来计算GC。
>
> **单次仿真循环流程 (for step = 1 to n_steps):**
>
> 1. **用户批次抽样**:
>    - 从 `train-loader` 中每步抽取一个 `batch_size` 的用户。（GT和GC的仿真在每一步都使用**完全相同**的用户批次）。
> 2. **候选视频生成**:
>    - 对于批次中的每一个用户，从其 `Video-list` 中，筛选出 `mask=0` 且 `used=0` 的视频（`used`状态是两个流程共享的）。
>    - 从筛选后的列表中，抽取 `n_candidate` 个视频作为该用户的候选推荐池。
> 3. **模型预测与加权排序**:
>    - 使用当前的 `predicting model` 对 `batch_size * n_candidate` 个候选视频进行打分，得到基础预测值 `Label`。predicting model的输入是user特征+video特征，选用的特征在config中定义。play_time尺度很大，训练中使用logMAE损失函数
>    - 根据当前仿真流程的身份（是Treatment还是Control），使用对应的 `alpha` 参数（vecalpha∗T 或 vecalpha∗C）计算最终排序分 `score`。例如：`score = alpha · Label`。
>    - 对每个用户的候选视频，根据 `score` 从高到低排序。
> 4. **选出胜出视频**:
>    - 为每个用户选出排序后 `score` 最高的视频作为“胜出者”。
> 5. **获取真实反馈与模型训练**:
>    - 查找这批胜出视频在真实交互数据中的特征 `X` 和真实 `Label` (Y)。
>    - 将 `(X, Y)` 数据对用于**训练共享的 `predicting model`**。
>    - **同时，将这批胜出视频的真实 `Label` (Y) 累加到当前仿真流程的总收益中**（GT流程累加到`total_label_T`，GC流程累加到`total_label_C`）。
> 6. **更新状态**:
>    - 将被推荐过的视频的 `used` 标记置为1。
> 7. **保存与续训**:
>    - 循环结束后，保存共享的模型参数、优化器状态和当前 `step`数，以便能够接续训练。
> 8. **Validation**: 每n步（在config中定义）使用测试集validate一次（validate不考虑used和masked，user从val_loader中获取，其余流程一致）。
>
> ### 三、 模型、配置与文件结构
>
> #### 模型
>
> - **Predicting model**: 核心的共享模型，输入特征 `X`，输出基础预测 `Label`。它在两个并行的仿真流程中被同步更新。
>
> #### 配置文件 (`config.yaml`)
>
> `config.yaml`通过顶层的`mode`键来决定本次实验运行的模式，并读取对应模式下的参数配置。
>
> - **`mode`**: (顶层键) 字符串，指定实验模式，如 `'global'`, `'weighting'`, `'splitting'`等。
> - **`global`**: (顶层配置块) **仅在`mode: 'global'`时生效**。此配置块表示global mode下的参数设置，与之平行的将来会有weighting、splitting配置块：
>   - `user_p_val`: 验证集用户比例。
>   - `batchsize`: 每步抽样的用户数。
>   - `n_candidate`: 每个用户的候选视频数。
>   - `n_steps`: 仿真总步数。
> - **`feature`**: (顶层键) 声明模型使用的数值特征和分类特征。
> - **`label`**: (顶层键) 定义预测的目标（`binary`或`numerical`）。
> - **`pretrain`**: (顶层配置块) 定义预训练阶段的参数，如`batch_size`, `epochs`。
> - **`recommender`**: (顶层配置块) **实验的核心**，定义了两种策略的`alpha`权重。
>   - `alpha_T: [w1, w2, ...]`
>   - `alpha_C: [w1, w2, ...]`
>
> #### 文件结构与日志
>
> 项目的根目录为 `base`，其下包含了配置、数据、代码和结果等所有相关文件。
>
> ```
> base/
> ├── configs/
> │   └── experiment.yaml        # 实验配置文件
> ├── data/
> │   └── KuaiRand/
> │       ├── Pure/data             # KuaiRand-Pure 原始数据集
> │       ├── 1K/data
> │       ├── 27K/data
> │            └── .csv           # 经过预处理、合并后的特征与标签数据
> ├── libs/
> │   └── ...                    # 主体逻辑实现
> 	└── modes
> 		└── global.py
> 		└── weighting.py
> 		└── splitting.py
> 		└── ...
> └── results/
>     └── 20250801_2210/         # 一次具体实验的结果，以时间戳命名
>         ├── run.log            # 本次实验的完整日志输出
>         ├── result.json        # 过程指标和评估指标（GT, GC, GTE等）
>         ├── plot.svg           # 实验过程中的指标变化可视化图表
>         └── checkpoints/       # 存放模型参数和优化器状态
>             └── step_1000.pt
> ```
>
> **日志 (`run.log`)** 会记录实验过程中的关键信息：
>
> - 数据集概览（使用的特征、标签等）。
> - 预训练过程 (`[pretrain] epoch 1/50 ...`)。
> - 仿真训练过程 (`[train] step 1/1000, ...`)。
> - 验证过程中的指标 (`[validate] step 100/1000, ...`)。
> - 最好尽可能详细记录更多，开始进行xx，完成xx
> - 最终的 GTE 评估结果。
>
> **未来展望 (伏笔)**
>
> 当前这个“global”模式的设计非常巧妙，它为后续更复杂的实验模式（如`splitting`模式）打下了坚实的基础。在未来的模式中，可以不再进行两次完整的仿真，而是在**每一个step内部**，将用户随机分到Treatment组或Control组，并使用各自的`alpha`进行推荐，甚至可以为两组分别维护两个不同的`predicting model`进行训练。

> 校对和修正以下和我意图不符的地方：
>
> - 获取数据集统计信息后打印于log；log消息的开头添加[xx（显示当前运行的环节、模块]
> - 特征的选取（config配置）请参考 数据集结构分析报告.md，
>   - 用户特征`user_active_degree`、视频基础特征`video_type`、`tag`是字符型类别变量，可以转化为哑变量，多少类就变为多少个onehot变量。
>   - 视频基础特征`upload_dt`是日期格式，对于预测没有作用，不使用这个特征。
>   - 各种id类变量不适合量化，也不需要，不作为特征使用。
>   - 所有使用的特征都在config中声明式定义，只分两类（数值和分类），未声明的特征不用。
>   - NA等缺失值作为一个新的类别；连续型变量则用0填充
> - label可定义多个，对应alpha也有这么多维数，这里使用click和playtime这两个label，playtime使用logMAE损失函数
>   - 每个label采用独立的预测模型，他们的结构定义作为config中model的子项；treatment实验（计算GT）和Control实验（计算GC）是使用同一个模型的2个实例
>
> 然后尝试运行global mode实验，并持续debug（bug处理要遵循实验合理，不能敷衍了事）

> - 调试直到项目跑通，并修复或添加以下：
> - alpha重复定义了，一般只在label项里定义即可
> - 添加结果画图程序
>   - playtime的预测趋向于0，是否是因为大部分真实playtime都是0，那么我希望log记录的playtime不再计算全部的平均值和MSE，而是记录非0的playtime的平均相对误差（百分比那种），画图相应调整为（比例、布局也调整适应）：
>   - 图块1：CTR AUC，包括train/val和treatment/control
>   - 图块2：CTR XXloss，包括train/val和treatment/control
>   - 图块3：playtime 平均相对误差（百分比），包括train/val和treatment/control
>   - 图块4：playtime XXloss，包括train/val和treatment/control
>   - 图块5：weightmodel AUC和Acurracy，包括train/val
>   - 图块6：weightmoel XXloss，包括train/val
> - /

>             # Treatment组推荐
>             recommendations_T = self.recommend(user_candidates.copy(), self.alpha_T)
>             
>             # Control组推荐
>             recommendations_C = self.recommend(user_candidates.copy(), self.alpha_C)
>             
>             # 收集真实反馈
>             user_ids_T = [rec[0] for rec in recommendations_T]
>             video_ids_T = [rec[1] for rec in recommendations_T]
>             true_labels_dict_T = self.data_methods.get_true_labels_dict(user_ids_T, video_ids_T)
>             
>             user_ids_C = [rec[0] for rec in recommendations_C]
>             video_ids_C = [rec[1] for rec in recommendations_C]
>             true_labels_dict_C = self.data_methods.get_true_labels_dict(user_ids_C, video_ids_C)
>             
>             # 训练模型（使用两组数据）
>             all_user_ids = user_ids_T + user_ids_C
>             all_video_ids = video_ids_T + video_ids_C
>             
>             # 合并标签
>             all_labels_dict = {}
>             for label_name in self.label_names:
>                 # 确保两组数据都有该标签
>                 if label_name in true_labels_dict_T and label_name in true_labels_dict_C:
>                     all_labels_dict[label_name] = np.concatenate([
>                         true_labels_dict_T[label_name], 
>                         true_labels_dict_C[label_name]
>                     ])
>             
>             # 训练每个模型
>             losses = self.train_step(optimizers, criteria, all_user_ids, all_video_ids, all_labels_dict)
>             
>             # 记录损失
>             for label_name, loss in losses.items():
>                 self.training_losses[label_name].append(loss)
>             
>             # 累积标签
>             for label_name in self.label_names:
>                 if label_name in true_labels_dict_T:
>                     self.total_labels_T[label_name] += true_labels_dict_T[label_name].sum()
>                 if label_name in true_labels_dict_C:
>                     self.total_labels_C[label_name] += true_labels_dict_C[label_name].sum()
>             
>             这一段的逻辑你背离了我的初衷，我希望的是把global mode的逻辑放在libs/exp_modes目录下的单独的global.py文件中，方便以后增加weighting.py\spliting.py……；global mode的逻辑是独立运行两次实验，**：一次全员使用处理组推荐参数的alpha (vecalpha∗T)来计算GT，一次全员使用对照组的alpha (vecalpha∗C)来计算GC。两次仿真没有交集，不要把他们混在一起训练，used也是独立的，不共享
